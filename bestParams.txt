RandomForestClassifier(bootstrap = True, criterion = entropy, max_depth = None, max_features = log2, min_samples_leaf = 1, min_samples_split = 9, n_estimators = 389, n_jobs = -1)
KNeighborsClassifier(algorithm = kd_tree, leaf_size = 25, n_neighbors = 19, p = 1, weights = distance)
KNeighborsClassifier(algorithm = kd_tree, leaf_size = 20, n_neighbors = 24, p = 1, weights = distance)
much sleep

LogisticRegression(tol = 0.0005, solver = lbfgs, penalty = l2, n_jobs = -1, multi_class = multinomial, max_iter = 180, intercept_scaling = 15, fit_intercept = True, dual = False, class_weight = balanced, C = 1000)
RandomForestClassifier(bootstrap = True, criterion = gini, max_depth = None, max_features = auto, min_samples_leaf = 1, min_samples_split = 7, n_estimators = 445, n_jobs = -1)
KNeighborsClassifier(algorithm = brute, leaf_size = 20, n_neighbors = 27, p = 1, weights = distance)
RandomForestClassifier(bootstrap = False, criterion = gini, max_depth = None, max_features = log2, min_samples_leaf = 4, min_samples_split = 7, n_estimators = 1776, n_jobs = -1)
RandomForestClassifier(bootstrap = True, criterion = gini, max_depth = None, max_features = log2, min_samples_leaf = 2, min_samples_split = 9, n_estimators = 1373, n_jobs = -1)
RandomForestClassifier(bootstrap = False, criterion = entropy, max_depth = None, max_features = log2, min_samples_leaf = 4, min_samples_split = 2, n_estimators = 914, n_jobs = -1)
36: RandomForestClassifier(bootstrap = False, criterion = gini, max_depth = None, max_features = auto, min_samples_leaf = 4, min_samples_split = 4, n_estimators = 1508, n_jobs = -1)
45: RandomForestClassifier(bootstrap = False, criterion = entropy, max_depth = None, max_features = auto, min_samples_leaf = 4, min_samples_split = 7, n_estimators = 709, n_jobs = -1)
1: LogisticRegression(tol = 0.00011, solver = saga, penalty = l1, n_jobs = -1, multi_class = multinomial, max_iter = 140, intercept_scaling = 0.002, fit_intercept = True, dual = False, class_weight = balanced, C = 1)
3: LogisticRegression(tol = 0.0005, solver = saga, penalty = l1, n_jobs = -1, multi_class = ovr, max_iter = 110, intercept_scaling = 1.1, fit_intercept = True, dual = False, class_weight = None, C = 100)
2: LogisticRegression(tol = 0.00011, solver = saga, penalty = l1, n_jobs = -1, multi_class = multinomial, max_iter = 100, intercept_scaling = 1.1, fit_intercept = True, dual = False, class_weight = None, C = 10)
3: LogisticRegression(tol = 0.0001, solver = lbfgs, penalty = l2, n_jobs = -1, multi_class = ovr, max_iter = 110, intercept_scaling = 0.2, fit_intercept = True, dual = False, class_weight = None, C = 10000)
2: LogisticRegression(tol = 0.0001, solver = newton-cg, penalty = l2, n_jobs = -1, multi_class = ovr, max_iter = 105, intercept_scaling = 1.1, fit_intercept = True, dual = False, class_weight = None, C = 10000)
3: LogisticRegression(tol = 0.00011, solver = saga, penalty = l1, n_jobs = -1, multi_class = multinomial, max_iter = 110, intercept_scaling = 1.2, fit_intercept = True, dual = False, class_weight = None, C = 10000)
1: LogisticRegression(tol = 0.001, solver = newton-cg, penalty = l2, n_jobs = -1, multi_class = multinomial, max_iter = 160, intercept_scaling = 1, fit_intercept = True, dual = False, class_weight = None, C = 1000)
2: LogisticRegression(tol = 0.00011, solver = newton-cg, penalty = l2, n_jobs = -1, multi_class = ovr, max_iter = 180, intercept_scaling = 0.2, fit_intercept = True, dual = False, class_weight = None, C = 10000)
3: LogisticRegression(tol = 0.0001, solver = lbfgs, penalty = l2, n_jobs = -1, multi_class = multinomial, max_iter = 180, intercept_scaling = 0.3, fit_intercept = True, dual = False, class_weight = None, C = 100)
2: LogisticRegression(tol = 0.0005, solver = sag, penalty = l2, n_jobs = -1, multi_class = multinomial, max_iter = 110, intercept_scaling = 2, fit_intercept = True, dual = False, class_weight = balanced, C = 10000)
1: LogisticRegression(tol = 9e-05, solver = sag, penalty = l2, n_jobs = -1, multi_class = ovr, max_iter = 110, intercept_scaling = 0.1, fit_intercept = True, dual = False, class_weight = balanced, C = 1)
1: LogisticRegression(tol = 0.0005, solver = newton-cg, penalty = l2, n_jobs = -1, multi_class = ovr, max_iter = 140, intercept_scaling = 0.01, fit_intercept = True, dual = False, class_weight = balanced, C = 10)
4: LogisticRegression(tol = 9e-05, solver = lbfgs, penalty = l2, n_jobs = -1, multi_class = multinomial, max_iter = 110, intercept_scaling = 15, fit_intercept = True, dual = False, class_weight = None, C = 10)
calin
1: LogisticRegression(tol = 0.00011, solver = lbfgs, penalty = l2, n_jobs = -1, multi_class = multinomial, max_iter = 140, intercept_scaling = 15, fit_intercept = True, dual = False, class_weight = balanced, C = 100)
18: RandomForestClassifier(bootstrap = True, criterion = entropy, max_depth = None, max_features = auto, min_samples_leaf = 1, min_samples_split = 6, n_estimators = 1941, n_jobs = -1)
3: KNeighborsClassifier(algorithm = ball_tree, leaf_size = 10, n_neighbors = 18, p = 1, weights = distance)
9: KNeighborsClassifier(algorithm = ball_tree, leaf_size = 35, n_neighbors = 29, p = 1, weights = distance)
206: BaggingClassifier(bootstrap = True, bootstrap_features = False, max_features = 0.6, max_samples = 0.3, n_estimators = 69, n_jobs = -1, oob_score = True)
29: BaggingClassifier(bootstrap = True, bootstrap_features = True, max_features = 0.7, n_estimators = 158, n_jobs = -1, oob_score = True)
322: BaggingClassifier(bootstrap = True, bootstrap_features = False, max_features = 0.5, n_estimators = 36, n_jobs = -1, oob_score = True)
1: Ridge(alpha = 0.008309941949353404, fit_intercept = True, max_iter = 836, normalize = True, solver = svd, tol = 9e-05)
10: Ridge(alpha = 0.008309941949353404, fit_intercept = True, max_iter = 1552, normalize = True, solver = lsqr, tol = 0.0001)
98: Ridge(alpha = 0.01, fit_intercept = True, max_iter = 1576, normalize = True, solver = lsqr, tol = 0.001)
3: Lasso(alpha = 0.00035707859649004625, fit_intercept = True, max_iter = 661, normalize = True, positive = False, selection = random, tol = 0.0005)
3: Lasso(alpha = 0.009115888299750819, fit_intercept = True, max_iter = 1100, normalize = False, positive = False, selection = random, tol = 1e-05)
40: Lasso(alpha = 0.0002704959730463137, fit_intercept = True, max_iter = 1698, normalize = True, positive = False, selection = random, tol = 0.001)
22: Lasso(alpha = 0.00018679135990207847, fit_intercept = True, max_iter = 1163, normalize = True, positive = False, selection = random, tol = 0.001)
28: ElasticNet(alpha = 0.009115888299750819, fit_intercept = True, l1_ratio = 0.9, max_iter = 1875, normalize = False, positive = False, selection = random, tol = 0.001)
28: ElasticNet(alpha = 0.01, fit_intercept = True, l1_ratio = 0.6, max_iter = 1429, normalize = False, positive = False, selection = random, tol = 0.001)
275: ElasticNet(alpha = 0.0002465811075822604, fit_intercept = True, l1_ratio = 0.9, max_iter = 1508, normalize = True, positive = False, selection = random, tol = 0.001)
135: KNeighborsRegressor(algorithm = ball_tree, leaf_size = 28, n_jobs = -1, n_neighbors = 22, p = 1, weights = uniform)
